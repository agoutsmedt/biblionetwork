#' If TRUE, the function ends by transforming the `from` and `to` columns in character, to make the
#' creation of a [tidygraph](https://tidygraph.data-imaginist.com/index.html) graph easier.
#'
#' @return A data.table with the articles identifiers in `from` and `to` columns, with the coupling strength measure in
#' another column. It also keeps a copy of `from` and `to` in the `Source` and `Target` columns. This is useful is you
#' are using the tidygraph package then, where `from` and `to` values are modified when creating a graph.
#'
#' @references
#' \insertAllCited{}
#'
#' @export
#' @import data.table
#' @import Rdpack
# Listing the variables not in the global environment to avoid a "note" saying "no visible binding for global variable ..." when using check()
# See https://www.r-bloggers.com/2019/08/no-visible-binding-for-global-variable/
id_ref <- id_art <- N <- Source <- Target <- weight <- nb_cit <- . <- nb_ref_Target <- nb_ref_Source <- NULL
# Making sure the table is a datatable
dt <- data.table::data.table(dt)
# Renaming and simplifying
data.table::setnames(dt, c(source,ref), c("id_art", "id_ref"))
dt <- dt[,c("id_art","id_ref")]
data.table::setkey(dt,id_ref,id_art)
# removing duplicated citations with exactly the same source and target
dt <- unique(dt)
# remove loop
dt <- dt[id_art!=id_ref]
# Computing how many items each citing document has (necessary for normalization later)
id_nb_ref <-  dt[,list(nb_ref = .N),by=id_art]
# Removing references cited only once:
dt <- dt[,N := .N, by = id_ref][N > 1][, list(id_art,id_ref)]
# Computing how many times each reference is cited
ref_nb_cit <-  dt[,list(nb_cit = .N),by=id_ref]
# Computing the total number of documents in the corpus.
nb_doc <-  dt[unique(id_art)][,list(n_document = .N)]
# Creating every combinaison of articles per references
bib_coup <- dt[,list(Target = rep(id_art[1:(length(id_art)-1)],(length(id_art)-1):1),
Source = rev(id_art)[sequence((length(id_art)-1):1)]),
by= id_ref]
# remove loop
bib_coup <- bib_coup[Source!=Target]
# Inverse Source and Target so that couple of Source/Target are always on the same side
bib_coup <- bib_coup[Source > Target, c("Target", "Source") := list(Source, Target)] # exchanging
###### Add columns with info for weighting
#Calculating the number of references in common and deleting the links between articles that share less than weight_threshold
bib_coup <- bib_coup[,N:= .N,by=list(Target,Source)][N>=weight_threshold]
# integrating the number of documents
bib_coup[,nb_doc:=nb_doc]
# merge the number of occurence of a ref in a document
bib_coup <-  merge(bib_coup, ref_nb_cit, by = "id_ref")
# merge the lenght of reference list
bib_coup <-  merge(bib_coup, id_nb_ref, by.x = "Target",by.y = "id_art" )
setnames(bib_coup,"nb_ref", "nb_ref_Target")
bib_coup <-  merge(bib_coup, id_nb_ref, by.x = "Source",by.y = "id_art" )
setnames(bib_coup,"nb_ref", "nb_ref_Source")
# CS
bib_coup[,weight := (sum(log(nb_doc/nb_cit))) / (nb_ref_Target*nb_ref_Source), .(Source,Target)]
# Keep only unique couple
#bib_coup <- bib_coup[, head(.SD, 1), .(Source,Target)]
# copying the Source and Target columns in case of using Tidygraph later
bib_coup[, `:=` (from = Source, to = Target)]
#Transforming in character
if(output_in_character == TRUE){
bib_coup$from <- as.character(bib_coup$Source)
bib_coup$to <- as.character(bib_coup$Target)
}
# return (bib_coup)
}
coupling_strength(Ref_stagflation, "Citing_ItemID_Ref","ItemID_Ref")
x = coupling_strength(Ref_stagflation, "Citing_ItemID_Ref","ItemID_Ref")
x
# Making sure the table is a datatable
dt <- data.table::data.table(Ref_stagflation)
dt
source="Citing_ItemID_Ref"
ref="ItemID_Ref"
# Renaming and simplifying
data.table::setnames(dt, c(source,ref), c("id_art", "id_ref"))
dt <- dt[,c("id_art","id_ref")]
data.table::setkey(dt,id_ref,id_art)
dt
# removing duplicated citations with exactly the same source and target
dt <- unique(dt)
# remove loop
dt <- dt[id_art!=id_ref]
# Computing how many items each citing document has (necessary for normalization later)
id_nb_ref <-  dt[,list(nb_ref = .N),by=id_art]
# Removing references cited only once:
dt <- dt[,N := .N, by = id_ref][N > 1][, list(id_art,id_ref)]
# Computing how many times each reference is cited
ref_nb_cit <-  dt[,list(nb_cit = .N),by=id_ref]
# Computing the total number of documents in the corpus.
nb_doc <-  dt[unique(id_art)][,list(n_document = .N)]
# Creating every combinaison of articles per references
bib_coup <- dt[,list(Target = rep(id_art[1:(length(id_art)-1)],(length(id_art)-1):1),
Source = rev(id_art)[sequence((length(id_art)-1):1)]),
by= id_ref]
# remove loop
bib_coup <- bib_coup[Source!=Target]
# Inverse Source and Target so that couple of Source/Target are always on the same side
bib_coup <- bib_coup[Source > Target, c("Target", "Source") := list(Source, Target)] # exchanging
bib_coup
bib_coup
weight_threshold = 1
###### Add columns with info for weighting
#Calculating the number of references in common and deleting the links between articles that share less than weight_threshold
bib_coup <- bib_coup[,N:= .N,by=list(Target,Source)][N>=weight_threshold]
# integrating the number of documents
bib_coup[,nb_doc:=nb_doc]
# merge the number of occurence of a ref in a document
bib_coup <-  merge(bib_coup, ref_nb_cit, by = "id_ref")
# merge the lenght of reference list
bib_coup <-  merge(bib_coup, id_nb_ref, by.x = "Target",by.y = "id_art" )
setnames(bib_coup,"nb_ref", "nb_ref_Target")
bib_coup <-  merge(bib_coup, id_nb_ref, by.x = "Source",by.y = "id_art" )
setnames(bib_coup,"nb_ref", "nb_ref_Source")
bib_coup
# CS
bib_coup[,weight := (sum(log(nb_doc/nb_cit))) / (nb_ref_Target*nb_ref_Source), .(Source,Target)]
bib_coup
# copying the Source and Target columns in case of using Tidygraph later
bib_coup[, `:=` (from = Source, to = Target)]
bib_coup
output_in_character = TRUE
#Transforming in character
if(output_in_character == TRUE){
bib_coup$from <- as.character(bib_coup$from)
bib_coup$to <- as.character(bib_coup$to)
}
bib_coup
return (bib_coup[, c("from","to","weight","Source","Target")])
bib_coup[, c("from","to","weight","Source","Target")]
# Listing the variables not in the global environment to avoid a "note" saying "no visible binding for global variable ..." when using check()
# See https://www.r-bloggers.com/2019/08/no-visible-binding-for-global-variable/
id_ref <- id_art <- N <- Source <- Target <- weight <- nb_cit <- . <- nb_ref_Target <- nb_ref_Source <- NULL
# Making sure the table is a datatable
dt <- data.table::data.table(Ref_stagflation)
dt
# Renaming and simplifying
data.table::setnames(dt, c(source,ref), c("id_art", "id_ref"))
dt <- dt[,c("id_art","id_ref")]
data.table::setkey(dt,id_ref,id_art)
# removing duplicated citations with exactly the same source and target
dt <- unique(dt)
# remove loop
dt <- dt[id_art!=id_ref]
# Computing how many items each citing document has (necessary for normalization later)
id_nb_ref <-  dt[,list(nb_ref = .N),by=id_art]
# Removing references cited only once:
dt <- dt[,N := .N, by = id_ref][N > 1][, list(id_art,id_ref)]
# Computing how many times each reference is cited
ref_nb_cit <-  dt[,list(nb_cit = .N),by=id_ref]
# Computing the total number of documents in the corpus.
nb_doc <-  dt[unique(id_art)][,list(n_document = .N)]
# Creating every combinaison of articles per references
bib_coup <- dt[,list(Target = rep(id_art[1:(length(id_art)-1)],(length(id_art)-1):1),
Source = rev(id_art)[sequence((length(id_art)-1):1)]),
by= id_ref]
# remove loop
bib_coup <- bib_coup[Source!=Target]
# Inverse Source and Target so that couple of Source/Target are always on the same side
bib_coup <- bib_coup[Source > Target, c("Target", "Source") := list(Source, Target)] # exchanging
###### Add columns with info for weighting
#Calculating the number of references in common and deleting the links between articles that share less than weight_threshold
bib_coup <- bib_coup[,N:= .N,by=list(Target,Source)][N>=weight_threshold]
# integrating the number of documents
bib_coup[,nb_doc:=nb_doc]
# merge the number of occurence of a ref in a document
bib_coup <-  merge(bib_coup, ref_nb_cit, by = "id_ref")
# merge the lenght of reference list
bib_coup <-  merge(bib_coup, id_nb_ref, by.x = "Target",by.y = "id_art" )
setnames(bib_coup,"nb_ref", "nb_ref_Target")
bib_coup <-  merge(bib_coup, id_nb_ref, by.x = "Source",by.y = "id_art" )
setnames(bib_coup,"nb_ref", "nb_ref_Source")
# CS
bib_coup[,weight := (sum(log(nb_doc/nb_cit))) / (nb_ref_Target*nb_ref_Source), .(Source,Target)]
# copying the Source and Target columns in case of using Tidygraph later
bib_coup[, `:=` (from = Source, to = Target)]
#Transforming in character
if(output_in_character == TRUE){
bib_coup$from <- as.character(bib_coup$from)
bib_coup$to <- as.character(bib_coup$to)
}
bib_coup[, c("from","to","weight","Source","Target")]
load_all()
library(devtools)
load_all()
load("~/MEGA/Research/R/Packages/biblionetwork/data/Ref_stagflation.rda")
coupling_strength(Ref_stagflation,"Citing_ItemID_Ref","ItemID_Ref")
document()
check()
Rdpack::viewRd()
Rdpack::viewRd("./man/coupling_strength.Rd")
Rdpack::viewRd("./man/coupling_strength.Rd")
?coupling_strength
document()
Rdpack::viewRd("./man/coupling_strength.Rd")
Rdpack::viewRd("./man/coupling_strength.Rd", ttype = "html")
Rdpack::viewRd("./man/coupling_strength.Rd", type = "html")
document()
install()
document()
?coupling_strength()
Rdpack::viewRd("./man/coupling_strength.Rd", type = "html")
document()
Rdpack::viewRd("./man/coupling_strength.Rd", type = "html")
?coupling_strength
use_r("coupling_entity")
dt = Ref_stagflation
# Making sure the table is a datatable
dt <- data.table(dt)
dt
# Renaming, calculating number of articles and simplifying
setnames(dt, c(source,entity,ref), c("id_art","entity", "id_ref"))
entity = "Author"
# Renaming, calculating number of articles and simplifying
setnames(dt, c(source,entity,ref), c("id_art","entity", "id_ref"))
source = "Citing_ItemID_Ref"
ref = "ItemID_Ref"
# Renaming, calculating number of articles and simplifying
setnames(dt, c(source,entity,ref), c("id_art","entity", "id_ref"))
dt
load("~/MEGA/Research/R/Packages/biblionetwork/data/Nodes_stagflation.rda")
x = merge(Ref_stagflation, Nodes_stagflation, by.x = "Citing_ItemID_Ref", by.y = "ItemID_Ref")
View(x)
entity = "Author.y"
# Making sure the table is a datatable
dt <- data.table(x)
dt
# Renaming, calculating number of articles and simplifying
setnames(dt, c(source,entity,ref), c("id_art","entity", "id_ref"))
# Calculating the total number of articles in the data frame
nb_doc <-  length(unique(dt[,id_art]))
nb_doc
# Computing how many times each document is cited (by citing article, not by entity, to avoid double-counting)
ref_nb_cit <-  unique(unique(dt[,c("id_art","id_ref")])[,list(nb_cit = .N),by=id_ref])
ref_nb_cit
# cleaning and setting the key
dt <- dt[,list(entity,id_ref)]
setkey(dt,id_ref,entity)
dt
# calculating the number of ref per-entity and the number of time a ref is cited by an entity
dt <- unique(dt[, nb_ref := .N, by = "entity"][, nb_cit_author := .N, by = c("entity","id_ref")])
dt
dt <- dt[, nb_author := .N, by = c("id_ref","entity")]
dt
dt
# Removing references cited by only one entity
test <- dt[,nb_cit_alt := .N, by = id_ref][nb_cit_alt > 1]
test
test <- dt[,nb_cit_alt := .N, by = id_ref][nb_author > 1]
test
# Making sure the table is a datatable
dt <- data.table(x)
# Renaming, calculating number of articles and simplifying
setnames(dt, c(source,entity,ref), c("id_art","entity", "id_ref"))
# Calculating the total number of articles in the data frame
nb_doc <-  length(unique(dt[,id_art]))
# Computing how many times each document is cited (by citing article, not by entity, to avoid double-counting)
ref_nb_cit <-  unique(unique(dt[,c("id_art","id_ref")])[,list(nb_cit = .N),by=id_ref])
# cleaning and setting the key
dt <- dt[,list(entity,id_ref)]
setkey(dt,id_ref,entity)
dt <- dt[, nb_author := .N, by = c("id_ref","entity")]
dt
dt
# calculating the number of ref per-entity and the number of time a ref is cited by an entity
dt <- unique(dt[, nb_ref := .N, by = "entity"][, nb_cit_author := .N, by = c("entity","id_ref")])
test <- dt[,nb_cit_alt := .N, by = id_ref][nb_author > 1]
test
# Making sure the table is a datatable
dt <- data.table(x)
# Renaming, calculating number of articles and simplifying
setnames(dt, c(source,entity,ref), c("id_art","entity", "id_ref"))
# Calculating the total number of articles in the data frame
nb_doc <-  length(unique(dt[,id_art]))
# Computing how many times each document is cited (by citing article, not by entity, to avoid double-counting)
ref_nb_cit <-  unique(unique(dt[,c("id_art","id_ref")])[,list(nb_cit = .N),by=id_ref])
# cleaning and setting the key
dt <- dt[,list(entity,id_ref)]
setkey(dt,id_ref,entity)
# calculating the number of ref per-entity and the number of time a ref is cited by an entity
dt <- unique(dt[, nb_ref := .N, by = "entity"][, nb_cit_author := .N, by = c("entity","id_ref")])
dt <- dt[, nb_entity := .N, by = c("id_ref")]
dt
dt
# Removing references cited by only one entity
test <- dt[,nb_cit_alt := .N, by = id_ref][nb_cit_alt > 1]
test
test <- dt[,nb_cit_alt := .N, by = id_ref][nb_entity > 1]
test
# Removing references cited by only one entity
test <- dt[,nb_cit_alt := .N, by = id_ref][nb_ref > 1]
test
# Making sure the table is a datatable
dt <- data.table(x)
# Renaming, calculating number of articles and simplifying
setnames(dt, c(source,entity,ref), c("id_art","entity", "id_ref"))
# Calculating the total number of articles in the data frame
nb_doc <-  length(unique(dt[,id_art]))
# Computing how many times each document is cited (by citing article, not by entity, to avoid double-counting)
ref_nb_cit <-  unique(unique(dt[,c("id_art","id_ref")])[,list(nb_cit = .N),by=id_ref])
# cleaning and setting the key
dt <- dt[,list(entity,id_ref)]
setkey(dt,id_ref,entity)
# calculating the number of ref per-entity and the number of time a ref is cited by an entity
dt <- unique(dt[, nb_ref := .N, by = "entity"][, nb_cit_entity := .N, by = c("entity","id_ref")])
# calculating the number of entities citing a ref and removing refs cited by only one entity
dt <- dt[,nb_entity := .N, by = id_ref][nb_entity > 1]
dt
# Creating every combinaison of articles per references
dt_reduce <- dt[, list(entity,id_ref)]
bib_coup <- dt_reduce[,list(Target = rep(authors[1:(length(authors)-1)],(length(authors)-1):1),
Source = rev(authors)[sequence((length(authors)-1):1)]),
by= id_ref]
bib_coup <- dt_reduce[,list(Target = rep(entity[1:(length(authors)-1)],(length(entity)-1):1),
Source = rev(entity)[sequence((length(entity)-1):1)]),
by= id_ref]
bib_coup <- dt_reduce[,list(Target = rep(entity[1:(length(entity)-1)],(length(entity)-1):1),
Source = rev(entity)[sequence((length(entity)-1):1)]),
by= id_ref]
# remove loop
bib_coup <- bib_coup[Source!=Target]
# Inverse Source and Target so that couple of Source/Target are always on the same side
bib_coup <- bib_coup[Source > Target, c("Target", "Source") := list(Source, Target)] # exchanging
weight_threshold = 1
###### Add columns with info for weighting
#Calculating the number of references in common and deleting the links between articles that share less than weight_threshold
bib_coup <- bib_coup[,N:= .N,by=list(Target,Source)][N>=weight_threshold]
# nb_doc
bib_coup[,nb_doc:=nb_doc]
bib_coup
# merge the number of occurence of a ref in a document
bib_coup <-  merge(bib_coup, ref_nb_cit, by = "id_ref")
# merge the lenght of reference list
bib_coup <-  merge(bib_coup, unique(dt[,c("entity","nb_ref")]), by.x = "Target",by.y = "entity" )
setnames(bib_coup,"nb_ref", "nb_ref_Target")
bib_coup <-  merge(bib_coup, unique(dt[,c("entity","nb_ref")]), by.x = "Source",by.y = "entity" )
setnames(bib_coup,"nb_ref", "nb_ref_Source")
# merge the number of times a ref is cited by an author
bib_coup <-  merge(bib_coup, unique(dt[,c("entity","id_ref","nb_cit_entity")]), by.x = c("Target","id_ref"),by.y = c("entity","id_ref"))
setnames(bib_coup,"nb_cit_entity", "nb_cit_entity_Target")
bib_coup <-  merge(bib_coup, unique(dt[,c("entity","id_ref","nb_cit_entity")]), by.x = c("Source","id_ref"),by.y = c("entity","id_ref"))
setnames(bib_coup,"nb_cit_entity", "nb_cit_entity_Source")
bib_coup
method = "coupling_strength"
if(method == "coupling_strength"){
return(bib_coup[,weight := (sum(min(nb_cit_entity_Target,nb_cit_entity_Source)*log(nb_doc/nb_cit))) / (nb_ref_Target*nb_ref_Source), .(Source,Target)])
}
if(method == "coupling_strength"){
return(bib_coup[,weight := (sum(min(nb_cit_entity_Target,nb_cit_entity_Source)*log(nb_doc/nb_cit))) / (nb_ref_Target*nb_ref_Source), .(Source,Target)])
} else {
return(bib_coup[,weight := sum(min(nb_cit_entity_Target,nb_cit_entity_Source))/sqrt(nb_ref_Target*nb_ref_Source), .(Source,Target)])
}
if(method == "coupling_strength"){
return (bib_coup[,weight := (sum(min(nb_cit_entity_Target,nb_cit_entity_Source)*log(nb_doc/nb_cit))) / (nb_ref_Target*nb_ref_Source), .(Source,Target)])
} else {
return (bib_coup[,weight := sum(min(nb_cit_entity_Target,nb_cit_entity_Source))/sqrt(nb_ref_Target*nb_ref_Source), .(Source,Target)])
}
if(method == "coupling_strength"){
bib_coup[,weight := (sum(min(nb_cit_entity_Target,nb_cit_entity_Source)*log(nb_doc/nb_cit))) / (nb_ref_Target*nb_ref_Source), .(Source,Target)]
} else {
bib_coup[,weight := sum(min(nb_cit_entity_Target,nb_cit_entity_Source))/sqrt(nb_ref_Target*nb_ref_Source), .(Source,Target)]
}
bib_coup
bib_coup <- dt_reduce[,list(Target = rep(entity[1:(length(entity)-1)],(length(entity)-1):1),
Source = rev(entity)[sequence((length(entity)-1):1)]),
by= id_ref]
# remove loop
bib_coup <- bib_coup[Source!=Target]
# Inverse Source and Target so that couple of Source/Target are always on the same side
bib_coup <- bib_coup[Source > Target, c("Target", "Source") := list(Source, Target)] # exchanging
###### Add columns with info for weighting
#Calculating the number of references in common and deleting the links between articles that share less than weight_threshold
bib_coup <- bib_coup[,N:= .N,by=list(Target,Source)][N>=weight_threshold]
# nb_doc
bib_coup[,nb_doc:=nb_doc]
# merge the number of occurence of a ref in a document
bib_coup <-  merge(bib_coup, ref_nb_cit, by = "id_ref")
# merge the lenght of reference list
bib_coup <-  merge(bib_coup, unique(dt[,c("entity","nb_ref")]), by.x = "Target",by.y = "entity" )
setnames(bib_coup,"nb_ref", "nb_ref_Target")
bib_coup <-  merge(bib_coup, unique(dt[,c("entity","nb_ref")]), by.x = "Source",by.y = "entity" )
setnames(bib_coup,"nb_ref", "nb_ref_Source")
# merge the number of times a ref is cited by an author
bib_coup <-  merge(bib_coup, unique(dt[,c("entity","id_ref","nb_cit_entity")]), by.x = c("Target","id_ref"),by.y = c("entity","id_ref"))
setnames(bib_coup,"nb_cit_entity", "nb_cit_entity_Target")
bib_coup <-  merge(bib_coup, unique(dt[,c("entity","id_ref","nb_cit_entity")]), by.x = c("Source","id_ref"),by.y = c("entity","id_ref"))
setnames(bib_coup,"nb_cit_entity", "nb_cit_entity_Source")
method = "Other"
if(method == "coupling_strength"){
bib_coup[,weight := (sum(min(nb_cit_entity_Target,nb_cit_entity_Source)*log(nb_doc/nb_cit))) / (nb_ref_Target*nb_ref_Source), .(Source,Target)]
} else {
bib_coup[,weight := sum(min(nb_cit_entity_Target,nb_cit_entity_Source))/sqrt(nb_ref_Target*nb_ref_Source), .(Source,Target)]
}
bib_coup
bib_coup <- unique(bib_coup[, c("from","to","weight","Source","Target")])
bib_coup$from <- as.character(bib_coup$Source)
bib_coup$to <- as.character(bib_coup$Target)
bib_coup <- unique(bib_coup[, c("from","to","weight","Source","Target")])
bib_coup
# Making sure the table is a datatable
dt <- data.table(x)
# Renaming, calculating number of articles and simplifying
setnames(dt, c(source,entity,ref), c("id_art","entity", "id_ref"))
# Calculating the total number of articles in the data frame
nb_doc <-  length(unique(dt[,id_art]))
# Computing how many times each document is cited (by citing article, not by entity, to avoid double-counting)
ref_nb_cit <-  unique(unique(dt[,c("id_art","id_ref")])[,list(nb_cit = .N),by=id_ref])
# cleaning and setting the key
dt <- dt[,list(entity,id_ref)]
setkey(dt,id_ref,entity)
# calculating the number of ref per-entity and the number of time a ref is cited by an entity
dt <- unique(dt[, nb_ref := .N, by = "entity"][, nb_cit_entity := .N, by = c("entity","id_ref")])
# calculating the number of entities citing a ref and removing refs cited by only one entity
dt <- dt[,nb_entity := .N, by = id_ref][nb_entity > 1]
# Creating every combinaison of articles per references
dt_reduce <- dt[, list(entity,id_ref)]
bib_coup <- dt_reduce[,list(Target = rep(entity[1:(length(entity)-1)],(length(entity)-1):1),
Source = rev(entity)[sequence((length(entity)-1):1)]),
by= id_ref]
# remove loop
bib_coup <- bib_coup[Source!=Target]
# Inverse Source and Target so that couple of Source/Target are always on the same side
bib_coup <- bib_coup[Source > Target, c("Target", "Source") := list(Source, Target)] # exchanging
###### Add columns with info for weighting
#Calculating the number of references in common and deleting the links between articles that share less than weight_threshold
bib_coup <- bib_coup[,N:= .N,by=list(Target,Source)][N>=weight_threshold]
# nb_doc
bib_coup[,nb_doc:=nb_doc]
# merge the number of occurence of a ref in a document
bib_coup <-  merge(bib_coup, ref_nb_cit, by = "id_ref")
# merge the lenght of reference list
bib_coup <-  merge(bib_coup, unique(dt[,c("entity","nb_ref")]), by.x = "Target",by.y = "entity" )
setnames(bib_coup,"nb_ref", "nb_ref_Target")
bib_coup <-  merge(bib_coup, unique(dt[,c("entity","nb_ref")]), by.x = "Source",by.y = "entity" )
setnames(bib_coup,"nb_ref", "nb_ref_Source")
# merge the number of times a ref is cited by an author
bib_coup <-  merge(bib_coup, unique(dt[,c("entity","id_ref","nb_cit_entity")]), by.x = c("Target","id_ref"),by.y = c("entity","id_ref"))
setnames(bib_coup,"nb_cit_entity", "nb_cit_entity_Target")
bib_coup <-  merge(bib_coup, unique(dt[,c("entity","id_ref","nb_cit_entity")]), by.x = c("Source","id_ref"),by.y = c("entity","id_ref"))
setnames(bib_coup,"nb_cit_entity", "nb_cit_entity_Source")
if(method == "coupling_strength"){
bib_coup[,weight := (sum(min(nb_cit_entity_Target,nb_cit_entity_Source)*log(nb_doc/nb_cit))) / (nb_ref_Target*nb_ref_Source), .(Source,Target)]
} else {
bib_coup[,weight := sum(min(nb_cit_entity_Target,nb_cit_entity_Source))/sqrt(nb_ref_Target*nb_ref_Source), .(Source,Target)]
}
# copying the Source and Target columns in case of using Tidygraph later
bib_coup[, `:=` (from = Source, to = Target, method = method)]
#Transforming in character
if(output_in_character == TRUE){
bib_coup$from <- as.character(bib_coup$from)
bib_coup$to <- as.character(bib_coup$to)
}
bib_coup
document()
check()
document()
check()
document()
check()
load_all()
x = merge(Ref_stagflation, Nodes_stagflation, by.x = "Citing_ItemID_Ref", by.y = "ItemID_Ref")
coupling_entity(x, "Citing_ItemID_Ref","ItemID_Ref","Author.y", method = "coupling_angle")
version()
package_version()
knitr::opts_chunk$set(
collapse = TRUE,
comment = "#>",
fig.path = "man/figures/README-",
out.width = "100%"
)
library(biblionetwork)
package_version(biblionetwork)
package_version(biblionetwork)
library(biblionetwork)
edges <- biblio_coupling(Ref_stagflation, source = "Citing_ItemID_Ref", ref = "ItemID_Ref", normalized_weight_only = FALSE, weight_threshold = 1)
edges
edges <- biblio_coupling(Ref_stagflation, source = "Citing_ItemID_Ref", ref = "ItemID_Ref", normalized_weight_only = FALSE, weight_threshold = 3)
edges
edges <- coupling_strength(Ref_stagflation, source = "Citing_ItemID_Ref", ref = "ItemID_Ref", weight_threshold = 1)
edges
Ref_stagflation
package_version()
load_all()
load_all()
check()
document()
check()
document()
document()
check()
install()
library(biblionetwork)
edges <- biblio_coupling(Ref_stagflation, source = "Citing_ItemID_Ref", ref = "ItemID_Ref", normalized_weight_only = FALSE, weight_threshold = 1)
edges
install()
library(biblionetwork)
biblio_coupling(Ref_stagflation, source = "Citing_ItemID_Ref", ref = "ItemID_Ref", normalized_weight_only = FALSE, weight_threshold = 1)
library(biblionetwork)
coupling_strength(Ref_stagflation, source = "Citing_ItemID_Ref", ref = "ItemID_Ref", weight_threshold = 1)
library(biblionetwork)
# merging the references data with the citing author information in Nodes_stagflation
entity_citations <- merge(Ref_stagflation, Nodes_stagflation, by.x = "Citing_ItemID_Ref", by.y = "ItemID_Ref")
coupling_entity(entity_citations, source = "Citing_ItemID_Ref", ref = "ItemID_Ref", entity = "Author.y")
library(biblionetwork)
# merging the references data with the citing author information in Nodes_stagflation
entity_citations <- merge(Ref_stagflation, Nodes_stagflation, by.x = "Citing_ItemID_Ref", by.y = "ItemID_Ref")
coupling_entity(entity_citations, source = "Citing_ItemID_Ref", ref = "ItemID_Ref", entity = "Author.y", method = "coupling_angle")
check()
build_readme()
build_readme()
build_readme()
